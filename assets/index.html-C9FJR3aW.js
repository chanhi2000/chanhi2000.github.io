import{_ as f}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as k,d as a,b as e,g as h,t as m,au as n,av as i,w as p,e as r,r as l,o as b}from"./app-DM0WOK1z.js";const v={},K={id:"frontmatter-title-관련",tabindex:"-1"},y={class:"header-anchor",href:"#frontmatter-title-관련"},w={class:"table-of-contents"},R={id:"digitalocean-cloud-infrastructure-for-developers",tabindex:"-1"},A={class:"header-anchor",href:"#digitalocean-cloud-infrastructure-for-developers"},x={id:"naver-d2",tabindex:"-1"},D={class:"header-anchor",href:"#naver-d2"};function C(g,t){const d=l("SiteInfo"),o=l("VPCard"),s=l("VPIcon"),c=l("router-link"),u=l("TagLinks");return b(),k("div",null,[a("h1",K,[a("a",y,[a("span",null,m(g.$frontmatter.title)+" 관련",1)])]),e(d,{name:"DigitalOcean | Cloud Infrastructure for Developers",desc:"An ocean of simple, scalable cloud solutions.",url:"https://digitalocean.com/community/tutorials?sort_by=oldest",logo:"https://digitalocean.com/_next/static/media/favicon.594d6067.ico",preview:"https://www.digitalocean.com/_next/static/media/social-share-default.e8530e9e.jpeg"}),e(d,{name:"Learnk8s — the Kubernetes training company",desc:"We help you get started on your Kubernetes journey through comprehensive online, in person or remote training.",url:"https://learnk8s.io/archive",logo:"https://static.learnk8s.io/f7e5160d4744cf05c46161170b5c11c9.svg",preview:"https://static.learnk8s.io/6dbec52a8d352b7cd5625cf903bf4de4.png"}),e(o,n(i({title:"Popit | 전문 지식 공유를 위한 팀블로그",desc:"전문 지식 공유를 위한 팀블로그",link:"https://popit.kr/page/1",logo:"https://popit.kr/wp-content/uploads/2016/08/favicon_32x32.png",background:"rgba(0,21,41,0.2)"})),null,16),e(d,{name:"NAVER D2",desc:"",url:"https://d2.naver.com",lokafka:"d2.naver.com/favicon.ico",preview:"d2.naver.com/sitebanner.png"}),a("nav",w,[a("ul",null,[a("li",null,[e(c,{to:"#digitalocean-cloud-infrastructure-for-developers"},{default:p(()=>[e(s,{icon:"fa-brands fa-digital-ocean"}),t[0]||(t[0]=r("DigitalOcean | Cloud Infrastructure for Developers"))]),_:1})]),a("li",null,[e(c,{to:"#learnk8s-—-the-kubernetes-training-company"},{default:p(()=>t[1]||(t[1]=[r("Learnk8s — the Kubernetes training company")])),_:1})]),a("li",null,[e(c,{to:"#popit-전문-지식-공유를-위한-팀블로그"},{default:p(()=>t[2]||(t[2]=[r("Popit | 전문 지식 공유를 위한 팀블로그")])),_:1})]),a("li",null,[e(c,{to:"#naver-d2"},{default:p(()=>[e(s,{icon:"iconfont icon-naver"}),t[3]||(t[3]=r("NAVER D2"))]),_:1})])])]),t[6]||(t[6]=a("hr",null,null,-1)),a("h2",R,[a("a",A,[a("span",null,[e(s,{icon:"fa-brands fa-digital-ocean"}),t[4]||(t[4]=r("DigitalOcean | Cloud Infrastructure for Developers"))])])]),t[7]||(t[7]=a("blockquote",null,[a("p",null,"digitalocean.com")],-1)),e(o,n(i({title:"How to Integrate Existing Systems with Kafka Connect | DigitalOcean",desc:"In this tutorial, you’ll learn how to ingest data into Kafka topics using Kafka Connect - a tool used for reliably transferring data between Kafka and other …",link:"https://chanhi2000.github.io/bookshelf/digitalocean.com/how-to-integrate-existing-systems-with-kafka-connect.md",logo:"https://digitalocean.com/_next/static/media/favicon.594d6067.ico",background:"rgba(29,55,209,0.2)"})),null,16),e(o,n(i({title:"How To Set Up a Multi-Node Kafka Cluster using KRaft | DigitalOcean",desc:"Learn to create a Kafka cluster with KRaft for scalable, fault-tolerant real-time data processing in this step-by-step tutorial…",link:"https://chanhi2000.github.io/bookshelf/digitalocean.com/how-to-set-up-a-multi-node-kafka-cluster-using-kraft.md",logo:"https://digitalocean.com/_next/static/media/favicon.594d6067.ico",background:"rgba(29,55,209,0.2)"})),null,16),e(o,n(i({title:"How To Manage Kafka Programmatically | DigitalOcean",desc:"Discover how to master Kafka cluster management with KafkaAdminClient API, kcat CLI, and Kafka Cruise Control for efficient Kafka cluster management…",link:"https://chanhi2000.github.io/bookshelf/digitalocean.com/how-to-manage-kafka-programmatically.md",logo:"https://digitalocean.com/_next/static/media/favicon.594d6067.ico",background:"rgba(29,55,209,0.2)"})),null,16),t[8]||(t[8]=a("hr",null,null,-1)),t[9]||(t[9]=a("h2",{id:"learnk8s-—-the-kubernetes-training-company",tabindex:"-1"},[a("a",{class:"header-anchor",href:"#learnk8s-—-the-kubernetes-training-company"},[a("span",null,"Learnk8s — the Kubernetes training company")])],-1)),t[10]||(t[10]=a("blockquote",null,[a("p",null,"learnk8s.io")],-1)),e(o,n(i({title:"Scaling Microservices with Message Queues, Spring Boot and Kubernetes",desc:"Learn how to scale SpringBoot apps in Kubernetes using the autoscaler and a message broker such as Kafka, RabbitMQ or ActiveMQ.",link:"https://chanhi2000.github.io/bookshelf/learnk8s.io/scaling-spring-boot-microservices.md",logo:"https://static.learnk8s.io/f7e5160d4744cf05c46161170b5c11c9.svg",background:"rgba(86,154,209,0.2)"})),null,16),e(o,n(i({title:"Designing and testing a highly available Kafka cluster on Kubernetes",desc:"Learn how to design a Kafka cluster to achieve high availability using standard kubernetes resources and test how it tolerates maintenance and total node failures.",link:"https://chanhi2000.github.io/bookshelf/learnk8s.io/kafka-ha-kubernetes.md",logo:"https://static.learnk8s.io/f7e5160d4744cf05c46161170b5c11c9.svg",background:"rgba(86,154,209,0.2)"})),null,16),h(" END: learnk8s.io "),t[11]||(t[11]=a("hr",null,null,-1)),t[12]||(t[12]=a("h2",{id:"popit-전문-지식-공유를-위한-팀블로그",tabindex:"-1"},[a("a",{class:"header-anchor",href:"#popit-전문-지식-공유를-위한-팀블로그"},[a("span",null,"Popit | 전문 지식 공유를 위한 팀블로그")])],-1)),t[13]||(t[13]=a("blockquote",null,[a("p",null,"popit.kr")],-1)),e(o,n(i({title:"아파치 카프카(Apache Kafka)의 새로운 협의 프로토콜인 KRaft에 대해(1) | Popit",desc:"이번 글에서는 아파치 카프카(Apache Kafka)의 새로운 협의 프로토콜인 KRaft에 대해 다룰 예정입니다. 카프카를 사용하면서 초기에는 최신 버전의 릴리스를 추구했지만, 카프카가 점점 데이터 파이프라인의 중심이 되면서 보다 보수적으로 접근하게 되었습니다. 지금까지 KRaft에 대해 크게 고려하지 않았으나 이제는 KRaft에 대한 준비와 주키퍼 모드로 운영 중인 카프카를 마이그레이션 하는 방법 등에 대해서도 심도 있는 검토가 필요한 생각이 들었습니다. 이번에 새롭게 KRaft에 대한 자료 조사도 하고, 마이그레이션 테스트도 진행하면서 경험한 내용들을 간략히 공유하고자 합니다. 전체 글의 내용은 KRaft의 등장 배경과 중요성, 마이그레이션 전략, 릴리스 노트와 향후 계획 등을 설명하며, 총 2편으로 나누어 작성하겠습니다. 먼저 KRaft의 등장 배경과 중요성에 대해 살펴보겠습니다.",link:"https://chanhi2000.github.io/bookshelf/popit.kr/about-kraft-kafkas-new-consensus-protocol-1.md",logo:"https://popit.kr/wp-content/uploads/2016/08/favicon_32x32.png",background:"rgba(0,21,41,0.2)"})),null,16),e(o,n(i({title:"아파치 카프카(Apache Kafka)의 새로운 협의 프로토콜인 KRaft에 대해(2) | Popit",desc:"이번 글에서는 이전 글에 이어 KRaft의 구성 방법, 마이그레이션 전략, 릴리스 노트와 향후 계획에 대해 살펴보겠습니다. 아직 이전 글 을 읽어보지 못한 분들은 이전 글을 먼저 읽어보시기를 추천드립니다. KRaft의 구성 전통적인 주키퍼 모드를 사용하면서 많은 사용자들이 느꼈던 불편함 중 하나는 바로 주키퍼와 카프카 서버를 별도로 운영해야 한다는 점이었습니다. 이는 단순히 별도의 애플리케이션 운영 관리를 넘어서, 추가로 별도의 물리적 서버 자원의 할당까지 포함하고 있습니다. 제가 받은 많은 질문 중 하나도, 주키퍼 물리 서버의 할당과 관련된 주제로, 주키퍼와 카프카를 동일한 서버에서 실행해도 되는지에 관한 것이었습니다. 사실 주키퍼는 카프카를 관리하는 역할을 하므로, 이상적으로는 카프카와 분리된 별도의 서버에서 운영하는 것을 권장합니다. 하지만 이는 강제성을 요구하는 것도 아니고, 서버의 리소스 제약이 있는 경우 주키퍼와 카프카를 동일한 서버에서 실행할 수도 있습니다.  KRaft의 등장 이후 카프카 사용자들이 환영한 변화중 하나는 주키퍼의 의존성 제거입니다. 이는 애플리케이션의 관리 단순화뿐만 아니라, 물리적 서버의 리소스 절감도 가능하다고 생각했던 것",link:"https://chanhi2000.github.io/bookshelf/popit.kr/about-kraft-kafkas-new-consensus-protocol-2.md",logo:"https://popit.kr/wp-content/uploads/2016/08/favicon_32x32.png",background:"rgba(0,21,41,0.2)"})),null,16),t[14]||(t[14]=a("hr",null,null,-1)),a("h2",x,[a("a",D,[a("span",null,[e(s,{icon:"iconfont icon-naver"}),t[5]||(t[5]=r("NAVER D2"))])])]),e(o,n(i({title:"Kafka NetworkClient Internals | NAVER D2",desc:"Kafka NetworkClient Internals",link:"https://d2.naver.com/helloworld/0853669",logo:"d2.naver.com/favicon.ico",background:"rgba(54,235,127,0.2)"})),null,16),e(o,n(i({title:"일 3,000만 건의 네이버페이 주문 메시지를 처리하는 Kafka 시스템의 무중단 전환 사례 | NAVER D2",desc:"일 3,000만 건의 네이버페이 주문 메시지를 처리하는 Kafka 시스템의 무중단 전환 사례",link:"https://d2.naver.com/helloworld/8404108",logo:"d2.naver.com/favicon.ico",background:"rgba(54,235,127,0.2)"})),null,16),t[15]||(t[15]=a("hr",null,null,-1)),e(u)])}const P=f(v,[["render",C]]),I=JSON.parse('{"path":"/programming/java-kafka/articles/","title":"Article(s)","lang":"ko-KR","frontmatter":{"lang":"ko-KR","title":"Article(s)","description":"Kafka > Article(s)","icon":"fas fa-square-share-nodes","category":["Java","Kotlin","Kafka","Article(s)"],"tag":["blog","digitalocean.com","learnk8s.io","popit.kr","d2.naver.com","java","kotlin","kafka","apache-kafka"],"head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Article(s)\\",\\"image\\":[\\"\\"],\\"dateModified\\":null,\\"author\\":[]}"],["meta",{"property":"og:url","content":"https://chanhi2000.github.io/programming/java-kafka/articles/"}],["meta",{"property":"og:site_name","content":"chanhi2000"}],["meta",{"property":"og:title","content":"Article(s)"}],["meta",{"property":"og:description","content":"Kafka > Article(s)"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"ko-KR"}],["meta",{"property":"article:tag","content":"apache-kafka"}],["meta",{"property":"article:tag","content":"kafka"}],["meta",{"property":"article:tag","content":"kotlin"}],["meta",{"property":"article:tag","content":"java"}],["meta",{"property":"article:tag","content":"d2.naver.com"}],["meta",{"property":"article:tag","content":"popit.kr"}],["meta",{"property":"article:tag","content":"learnk8s.io"}],["meta",{"property":"article:tag","content":"digitalocean.com"}],["meta",{"property":"article:tag","content":"blog"}],[{"meta":null},{"property":"og:title","content":"kafka > Article(s)"},{"property":"og:description","content":"Article(s)"},{"property":"og:url","content":"https://chanhi2000.github.io/programming/java-kafka/articles/"}]]},"git":{},"readingTime":{"minutes":1.94,"words":582},"filePathRelative":"programming/java-kafka/articles/README.md"}');export{P as comp,I as data};
